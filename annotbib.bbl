\begin{thebibliography}{1}
\providecommand{\url}[1]{#1}
\csname url@rmstyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand\BIBentrySTDinterwordspacing{\spaceskip=0pt\relax}
\providecommand\BIBentryALTinterwordstretchfactor{4}
\providecommand\BIBentryALTinterwordspacing{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand\BIBforeignlanguage[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}

\bibitem{grig07}
\BIBentryALTinterwordspacing
D.~Grigorova and N.~Nikolov, ``Knowledge representation in systems with natural
  language interface,'' in \emph{Proceedings of the 2007 international
  conference on Computer systems and technologies}, ser. CompSysTech '07.\hskip
  1em plus 0.5em minus 0.4em\relax New York, NY, USA: ACM, 2007, pp.
  68:1--68:6. [Online]. Available:
  \url{http://doi.acm.org/10.1145/1330598.1330670}
\BIBentrySTDinterwordspacing
 \begin{quotation}\noindent This article compares several techniques for
  parsing and analyzing natural langauge sentences, comparing their advantages
  and disadvantages. Their comparisons are based upon the primary literature in
  which these techniques were introduced, rather than on a practical
  application. The paper also covers their implementation of a frame structure
  as a model for real-world objects and their algorithm for using that frame
  structure to build a semantic knowledge tree. Their analyzer allows the user
  to build a semantic representation of a sentence and its knowledge. I include
  this article for its comparison of analysis techniques and as a jumping-board
  to other literature. \end{quotation}

\bibitem{jura00}
D.~Jurafsky and J.~H. Martin, \emph{Speech and Language Processing}.\hskip 1em
  plus 0.5em minus 0.4em\relax Prentice Hall, 2000.
 \begin{quotation}\noindent This book is an introductory text to the field of
  speech and language processing, written to serve as the textbook for a course
  on the subject. Topics covered include statistical parsing, tagging,
  grammars, semantics and meaning and a cursory overview of knowledge
  representation. I used to source to learn the basics of natural langauge
  processing. Much of its focus is on lower-level ideas, leaving applications
  and complex knowledge representation to other texts. \end{quotation}

\bibitem{qu08}
Q.~Qu, J.~Qiu, C.~Sun, and Y.~Wang, ``Graph-based knowledge representation
  model and pattern retrieval,'' in \emph{Fuzzy Systems and Knowledge
  Discovery, 2008. FSKD '08. Fifth International Conference on}, vol.~5, 2008,
  pp. 541 --545.
 \begin{quotation}\noindent In this paper, the authors propose a model for
  representing and retreiving knowledge called a ``feature event dependency
  graph,'' in which events and their relevant links are represented as a
  weighted directional graph, allowing the graph to model time and dependency.
  They propose a set of algorithms for creating and using this graph. Knowledge
  patterns are retrieved as sets of event chains, keeping their context intact.
  The authors argue that their model offers better performance and ease-of-use
  than comparable efforts. The FEDG proposed here is similar to the technique I
  plan to use in modelling knowledge. \end{quotation}

\bibitem{sega09}
T.~Seagran, C.~Evans, and J.~Taylor, \emph{Programming the Semantic Web}.\hskip
  1em plus 0.5em minus 0.4em\relax O'Reilly Media, 2009.
 \begin{quotation}\noindent This book serves as an introduction to applications
  of semantic tools and provides a basic understanding of knowledge
  representation. Meant for developers of data-rich web applications, this text
  focuses entirely on the practical applications of the field, leaving
  theoretical insights to more academic sources. \end{quotation}

\end{thebibliography}
